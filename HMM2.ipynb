{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM2:\n",
    "        def __init__(self, state_list, observation_list,\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None):\n",
    "            \"\"\"Builds a new Hidden Markov Model\n",
    "            state_list is the list of state symbols [q_0...q_(N-1)]\n",
    "            observation_list is the list of observation symbols [v_0...v_(M-1)]\n",
    "            transition_proba is the transition probability matrix\n",
    "                [a_ij] a_ijk = Pr(Y_(t+1)=q_i|Y_t=q_j, Y_t-1=q_k)\n",
    "            observation_proba is the observation probablility matrix\n",
    "                [b_ki] b_ki = Pr(X_t=v_k|Y_t=q_i)\n",
    "            initial_state_proba is the initial state distribution\n",
    "                [pi_i] pi_i = Pr(Y_0=q_i)\"\"\"\n",
    "            print (\"HMM creating with: \")\n",
    "            self.N = len(state_list) # The number of states\n",
    "            self.M = len(observation_list) # The number of words in the vocabulary\n",
    "            print (str(self.N)+\" states\")\n",
    "            print (str(self.M)+\" observations\")\n",
    "            self.omega_Y = state_list # Keep the vocabulary of tags\n",
    "            self.omega_X = observation_list # Keep the vocabulary of tags\n",
    "            # Init. of the 3 distributions : observation, transition and initial states\n",
    "            if transition_proba is None:\n",
    "                self.transition_proba = np.zeros( (self.N, self.N, self.N), float) \n",
    "            else:\n",
    "                self.transition_proba=transition_proba\n",
    "            if observation_proba is None:\n",
    "                self.observation_proba = np.zeros( (self.M, self.N), float) \n",
    "            else:\n",
    "                self.observation_proba=observation_proba\n",
    "            if initial_state_proba is None:\n",
    "                self.initial_state_proba = np.zeros( (self.N, self.N), float ) \n",
    "            else:\n",
    "                self.initial_state_proba=initial_state_proba\n",
    "            # Since everything will be stored in numpy arrays, it is more convenient and compact to \n",
    "            # handle words and tags as indices (integer) for a direct access. However, we also need \n",
    "            # to keep the mapping between strings (word or tag) and indices. \n",
    "            self.__make_indexes()\n",
    "\n",
    "        def __make_indexes(self):\n",
    "            \"\"\"Creates the reverse table that maps states/observations names\n",
    "            to their index in the probabilities arrays\"\"\"\n",
    "            self.Y_index = {}\n",
    "            for i in range(self.N):\n",
    "                self.Y_index[self.omega_Y[i]] = i\n",
    "            self.X_index = {}\n",
    "            for i in range(self.M):\n",
    "                self.X_index[self.omega_X[i]] = i\n",
    "                \n",
    "        def __calculate_transition_proba(self,data):\n",
    "            \"\"\"calculate the transition matrix, never call it from outside\"\"\"\n",
    "            for word in range(len(data)):\n",
    "                actual_alphabet = None\n",
    "                last1_alphabet = None\n",
    "                for alphabet in range(0,len(data[word])):\n",
    "                    last2_alphabet = last1_alphabet #t-2\n",
    "                    last1_alphabet = actual_alphabet #t-1\n",
    "                    actual_alphabet = data[word][alphabet][1] #t\n",
    "                    if alphabet>1:    \n",
    "                        self.transition_proba[self.Y_index[actual_alphabet],self.Y_index[last1_alphabet],self.Y_index[last2_alphabet]] += 1\n",
    "        \n",
    "        def __calculate_observation_proba(self,data):\n",
    "            \"\"\"calculate de observation matrix, never call it from outside\"\"\"\n",
    "            for word in range(len(data)):\n",
    "                for alphabet in range(0,len(data[word])):\n",
    "                    real_alphabet = data[word][alphabet][1]\n",
    "                    observed_alphabet = data[word][alphabet][0]\n",
    "                    self.observation_proba[self.X_index[observed_alphabet],self.Y_index[real_alphabet]] += 1 \n",
    "        \n",
    "        def __calculate_initial_state(self,data):\n",
    "            \"\"\"calculate initial state distribution, never call it from outside\"\"\"\n",
    "            for word in range(len(data)):\n",
    "                if len(data[word])>1:\n",
    "                    initial1_alphabet = data[word][1][1]\n",
    "                    initial2_alphabet = data[word][0][1]\n",
    "                    self.initial_state_proba[self.Y_index[initial1_alphabet]][self.Y_index[initial2_alphabet]] += 1\n",
    "        \n",
    "        def __proba_normalization(self):\n",
    "            \"\"\"using for normalize the probability to 1, to use in the end of training, never call from it outside\"\"\"\n",
    "            for i in range(self.N):\n",
    "                for j in range(self.N):\n",
    "                    if self.transition_proba[:][i][j].sum()!=0:\n",
    "                        self.transition_proba[:][i][j]=self.transition_proba[:][i][j]/self.transition_proba[:][i][j].sum()\n",
    "                self.observation_proba[:][i]=self.observation_proba[:][i]/self.observation_proba[:][i].sum()\n",
    "            self.initial_state_proba = self.initial_state_proba / self.initial_state_proba.sum()\n",
    "                \n",
    "        def train(self, data):\n",
    "            \"\"\"a simple function to train the HMM\"\"\"\n",
    "            self.__calculate_transition_proba(data)\n",
    "            self.__calculate_observation_proba(data)\n",
    "            self.__calculate_initial_state(data)\n",
    "            self.__proba_normalization()\n",
    "            \n",
    "            \n",
    "        def viterbi(self, sequence):\n",
    "            \"\"\"second order viterbi algorithms implementation\"\"\"\n",
    "            \n",
    "            if len(sequence)==1:\n",
    "                return np.array([float(self.omega_Y.index(sequence[0]))])\n",
    "            \n",
    "            T1 = np.zeros((self.N, self.N, len(sequence)-1), float) \n",
    "            T2 = np.zeros((self.N, self.N, len(sequence)-1), float)\n",
    "            path = np.zeros(len(sequence))\n",
    "            \n",
    "            #inital state\n",
    "            for i in range(self.N):\n",
    "                for j in range(self.N):\n",
    "                    T1[i,j,0] = self.initial_state_proba[i][j]*self.observation_proba[self.omega_Y.index(sequence[1])][i]*self.observation_proba[self.omega_Y.index(sequence[0])][j]\n",
    "                    T2[i,j,0] = 0\n",
    "                    \n",
    "            #calculate other states\n",
    "            for t in range(1,len(sequence)-1):\n",
    "                for i in range(self.N):\n",
    "                    for j in range(self.N):\n",
    "                        #i is actual state t, j is t-1, k is t-2\n",
    "                        (T1[i,j,t],T2[i,j,t]) = max([(T1[j,k,t-1]*self.transition_proba[i][j][k]*self.observation_proba[state_liste.index(sequence[t+1])][i], k) for k in range(self.N)])  \n",
    "            z=np.argmax(T1[:,:,len(sequence)-2])\n",
    "            path[len(sequence)-1]=int(z/26)\n",
    "            path[len(sequence)-2]=z%26\n",
    "            \n",
    "            last_state1=int(z/26)\n",
    "            last_state2=z%26\n",
    "            for t in range(len(sequence)-2,0,-1):\n",
    "                z=T2[last_state1,last_state2,t]\n",
    "                #print (z)\n",
    "                path[t-1]=z\n",
    "                last_state1=last_state2\n",
    "                last_state2=int(z)\n",
    "                \n",
    "            return path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Typos_HMM2(HMM2):\n",
    "    \"\"\"An inherit class of HMM contains more function linked with typos correction\"\"\"\n",
    "    def __init__(self, state_list, observation_list,\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None):\n",
    "        super(Typos_HMM2, self).__init__(state_list, observation_list,\n",
    "                                       transition_proba, observation_proba, initial_state_proba)\n",
    "   \n",
    "    def test(self, test_data):\n",
    "        total_error = 0\n",
    "        error_corrected = 0\n",
    "        error_created = 0\n",
    "        total_alphabets = 0\n",
    "        for word in range(len(test_data)):\n",
    "            sequence=[]\n",
    "            for i in range(len(test_data[word])):\n",
    "                sequence.append(test_data[word][i][0])\n",
    "            new_sequence=self.viterbi(sequence).astype(int)\n",
    "            for i in range(len(test_data[word])):\n",
    "                if sequence[i] == test_data[word][i][1] and sequence[i] != self.omega_Y[new_sequence[i]]:\n",
    "                    error_created += 1\n",
    "                elif sequence[i] != test_data[word][i][1]:\n",
    "                    total_error+=1\n",
    "                    if test_data[word][i][1] == self.omega_Y[new_sequence[i]]:\n",
    "                        error_corrected += 1\n",
    "                total_alphabets += 1\n",
    "        print (\"The total error number in the test data is: \" + str(total_error))\n",
    "        print (\"The total error corrected by the first order HMM corector is: \" + str(error_corrected))\n",
    "        print (\"The total error created by the first order HMM corector is: \" + str(error_created))\n",
    "        print (\"The precision of the corrector is:\" + str(1-(total_error-error_corrected+error_created)/float(total_alphabets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./typos-data/train10.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('./typos-data/train20.pkl', 'rb') as f:\n",
    "    train_data2 = pickle.load(f)\n",
    "\n",
    "train_data.extend(train_data2)\n",
    "\n",
    "with open('./typos-data/test10.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "with open('./typos-data/test20.pkl', 'rb') as f:\n",
    "    test_data2 = pickle.load(f)\n",
    "    \n",
    "test_data.extend(test_data2)\n",
    "\n",
    "#create state and observation list\n",
    "state_liste = ['a','b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "observation_list = ['a','b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM creating with: \n",
      "26 states\n",
      "26 observations\n"
     ]
    }
   ],
   "source": [
    "Typo = Typos_HMM2(state_liste,observation_list)\n",
    "Typo.train(train_data)\n",
    "Typo.test(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
